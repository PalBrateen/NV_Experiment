{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample code to acquire frames from the camera..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not build capability 0x420830: ValueError('4327472 is not a valid EProp')\n",
      "WARNING:root:Could not build capability 0x420840: ValueError('4327488 is not a valid EProp')\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from hamamatsu.dcam import copy_frame, dcam, Stream\n",
    "%matplotlib qt\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "with dcam:  # runs the __enter__() method, returns the object of class DCAM\n",
    "    cam = dcam[0]    # camera object\n",
    "    with cam:\n",
    "        # print(cam.info)\n",
    "        # print(cam['image_hsize'].value, cam['image_vsize'].value) # looks like a dictionary\n",
    "\n",
    "        # Simple acquisition example\n",
    "        nb_frames = 1\n",
    "        cam[\"exposure_time\"] = 0.01\n",
    "        print(cam.camera_id)\n",
    "        frame_list = [];\n",
    "        frame_buffer_list=[]; print(\"Ready!!\")\n",
    "        with Stream(cam, nb_frames) as stream:\n",
    "                logging.info(\"start acquisition\")\n",
    "                cam.start()\n",
    "                print(\"Exposure time = \",cam[\"exposure_time\"].value)\n",
    "                for i, frame_buffer in enumerate(stream):\n",
    "                    frame = copy_frame(frame_buffer)\n",
    "                    frame_list.append(frame)\n",
    "                    frame_buffer_list.append(frame_buffer)\n",
    "                    # logging.info(\"acquired frame #%d/%d: %s\", i+1, nb_frames, frame)\n",
    "                    print(i)\n",
    "                # logging.info(\"finished acquisition\")\n",
    "                print(\"finished acquisition\")\n",
    "plt.figure(); plt.imshow(frame,cmap='gray', vmin=0, vmax=62255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hamamatsu.dcam.Device"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2 \n",
    " \n",
    "im_gray = cv2.imread(\"1.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "im_color = cv2.applyColorMap(im_gray, cv2.COLORMAP_JET)\n",
    "cv2.imshow(\"Image\",im_color)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\highgui\\src\\window.cpp:352: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b6b098f9e759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcap1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.0.1) C:\\ci\\opencv-suite_1573470242804\\work\\modules\\highgui\\src\\window.cpp:352: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def grab_frame(cap):\n",
    "    ret,frame = cap.read()\n",
    "    return cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#Initiate the two cameras\n",
    "cap1 = cv2.VideoCapture(0)\n",
    "cap2 = cv2.VideoCapture(1)\n",
    "\n",
    "#create two subplots\n",
    "fig, ax = plt.figure()\n",
    "\n",
    "#create two image plots\n",
    "im1 = ax.imshow(grab_frame(cap1))\n",
    "\n",
    "def update(i):\n",
    "    im1.set_data(grab_frame(cap1))\n",
    "    \n",
    "ani = FuncAnimation(plt.gcf(), update, interval=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIMPLIFIED - Sample code breakdown.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import logging\n",
    "from hamamatsu.dcam import *\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "%matplotlib qt\n",
    "\n",
    "dcam.__enter__()\n",
    "cam = dcam[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.open()\n",
    "cam.capabilities == {}\n",
    "# if not (cam.capabilities == {}):        # Camera initialize na hole 'cam.capabilities' empty thake.. tai ei check ta..\n",
    "    # print(\"Go ahead !!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam.open()\n",
    "cam[\"exposure_time\"] = 0.002\n",
    "cam[\"trigger_source\"] = 2\n",
    "cam[\"trigger_mode\"] = 6\n",
    "nb_frames = 10\n",
    "frame_list = []; frame_buffer_list=[]; print(\"Ready!!\")\n",
    "with Stream(cam, nb_frames) as stream:\n",
    "    logging.info(\"start acquisition\")\n",
    "    cam.start()\n",
    "    print(\"Exposure time [ms] = %0.2f\",(cam[\"exposure_time\"].value)*1e3)\n",
    "    for i, frame_buffer in enumerate(stream):\n",
    "        frame = copy_frame(frame_buffer)\n",
    "        frame_list.append(frame)\n",
    "        frame_buffer_list.append(frame_buffer)\n",
    "        # logging.info(\"acquired frame #%d/%d: %s\", i+1, nb_frames, frame)\n",
    "    # logging.info(\"finished acquisition\")\n",
    "    print(\"finished acquisition\")\n",
    "plt.figure(); plt.imshow(frame,cmap='gray', vmin=0, vmax=2**16)\n",
    "cam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.open()\n",
    "if not (cam.capabilities == {}):\n",
    "    print(\"\\x1b[38;2;250;250;0mGO\")\n",
    "    print(\"Exposure time [ms] = %0.2f\" % ((cam[\"exposure_time\"].value)*1e3))\n",
    "cam.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(frame_list)):\n",
    "    plt.figure(); \n",
    "    plt.imshow(frame_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample PB sequence - use loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the PB using the loop command\n",
    "# Simulating the actual code for capturing using the camera\n",
    "from spinapi import *\n",
    "\n",
    "# define the variables\n",
    "exp_time = 0.1 *ms\n",
    "t_AOM = 10 *us\n",
    "t_MW = 1000 *ns\n",
    "t_total_seq = t_AOM + t_MW\n",
    "N_repeat = round(exp_time / t_total_seq)\n",
    "# N_repeat = 5\n",
    "# PB connections\n",
    "camera = 2**0\n",
    "laser = 2**3\n",
    "MW = 2**2\n",
    "\n",
    "# program the pulse blaster\n",
    "pb_init();\n",
    "pb_get_version();\n",
    "pb_core_clock(500);\n",
    "\n",
    "pb_start_programming(PULSE_PROGRAM);\n",
    "\n",
    "start =         pb_inst_pbonly(camera,  Inst.CONTINUE, 0, 100*ns)\n",
    "loop_start =    pb_inst_pbonly(MW,      Inst.LOOP, N_repeat, t_MW)\n",
    "loop_end =      pb_inst_pbonly(laser,   Inst.END_LOOP, loop_start, t_AOM)\n",
    "seq_end =       pb_inst_pbonly(camera,  Inst.CONTINUE, 0, 100*ns)\n",
    "seq_end =       pb_inst_pbonly(0,  Inst.BRANCH, start, 100*ns)\n",
    "pb_stop_programming()\n",
    "pb_close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_init(); pb_start(); pb_close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_init(); pb_stop(); pb_close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corrected PB code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the camera and the PB have different time units...\n",
    "# PB base unit is ns, whereas camera base unit is seconds\n",
    "# times are defined wrt PB (default)\n",
    "# from spinapi import *     # spinapi cannot be imported w.o. the PB board\n",
    "import numpy as np\n",
    "ns=1; us=1e3; ms=1e6;\n",
    "t_exposure = 300 *ms # 300 ms (let)\n",
    "t_seq_total = 11 *us\n",
    "t_cam_response = 38.96 *us      # the response time of the camera when the 'trigger' and the 'sequence' needs to run together..\n",
    "\n",
    "N_trigger = np.floor(t_cam_response/t_seq_total)    # the fraction is rounded \"down\" so that the previous sequence runs for sometime and the remaining time is left empty... no sequence runs during that time..\n",
    "N_total = np.floor(t_exposure/t_seq_total)\n",
    "N_remaining = np.floor((t_exposure - 38.96*us)/t_seq_total)\n",
    "print((N_trigger + N_remaining) <= N_total)\n",
    "print(N_trigger)\n",
    "print(N_remaining)\n",
    "print(N_total)\n",
    "\n",
    "t_seq_total = [11 *us, 9*us]\n",
    "\n",
    "# below are two lists, with 2 elements each, one for signal and other for reference...\n",
    "# the operation should use np.floor() and not np.rint().. think..\n",
    "N_trigger = [int(np.floor(t_cam_response/element)) for element in t_seq_total]\n",
    "N_remaining = [int(np.floor((t_exposure - t_cam_response)/element)) for element in t_seq_total]\n",
    "N_total = [int(np.floor(t_exposure/element)) for element in t_seq_total]\n",
    "# defining the buffer times (in nanoseconds) -  time when there will be no sequence running - quiet period    \n",
    "t_buffer1 = (t_exposure - t_cam_response) - N_remaining[0]*t_seq_total[0]\n",
    "t_buffer2 = t_cam_response - N_trigger[0]*t_seq_total[0]\n",
    "t_buffer3 = (t_exposure - t_cam_response) - N_remaining[1]*t_seq_total[1]\n",
    "t_buffer4 = t_cam_response - N_trigger[1]*t_seq_total[1]\n",
    "t_buffer = [t_buffer1, t_buffer2, t_buffer3, t_buffer4]\n",
    "print(N_trigger)\n",
    "print(N_remaining)\n",
    "print(N_total)\n",
    "\n",
    "print(t_buffer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'the_list' & instructionList breakdown..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a sample 'the_list'\n",
    "the_list = [[[[10, 0, 0, 100.0], [8, 0, 0, 190.0], [8, 6, 0, 80.0]], 0, [], [], {0: 0.0, 1: 0.01, 2: 1.3}],\n",
    "     [[[8, 0, 0, 50.0], [2, 0, 0, 1290.0], [16, 6, 0, 8710.0]], 0, [], [], {0: 0.0, 1: 0.01, 2: 1.3}]]\n",
    "instructionList = [];\n",
    "for i in range(0, len(the_list)):   # len(the_list) = 2 (generally)... signal and reference...\n",
    "    instructionList.append(the_list[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[8, 0, 0, 50.0], [2, 0, 0, 1290.0], [16, 6, 0, 8710.0]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructionList[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving camera frames...\n",
    "In what follows, we try to save the frames captured from the camera to a file. First simulate a variable that stores the data from the camera."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating camera frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ekhane 'data_raw' ekta list with data from all the frames... save korte gele etake process kore arekta variable create korte hbe...\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "hsize = 3; vsize = 5; n_frames = 4; N_scanpts = 6;\n",
    "data_raw = [];\n",
    "for j in range(0, N_scanpts):\n",
    "    frames = np.zeros((hsize,vsize,n_frames));\n",
    "    for i in range(0,n_frames):\n",
    "        frame = np.random.rand(hsize, vsize)*2**16\n",
    "        frame = frame.astype(int)\n",
    "        frames[:,:,i] = frame       # numpy nd array\n",
    "    data_raw.append(frames)       # 'data_raw' ekta list.. tar bhetore 'frames' (3d array).. each element of all_frames belong to a specific scan_pt\n",
    "# for i in range(0,n_frames-1):\n",
    "# frames[:,:,0] = np.concatenate(tuple(frames[:,:,i] for i in range(0,n_frames-1)), axis=1)\n",
    "# how to process the data?? prepare the data such that there is minimum memory consumption\n",
    "print(len(data_raw[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ekhane 'data_raw' ekta numpy 2d-array... 'frames' ke 'flat' kore directly data_raw te store kora hochhe...\n",
    "# sva ekorte extra processing lagbe na... plot korte gele process korte hbe..\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "hsize = 3; vsize = 5; n_frames = 2; N_scanpts = 6;\n",
    "data_raw = np.zeros((hsize*N_scanpts,vsize*n_frames));\n",
    "for j in range(0, N_scanpts):\n",
    "    frames = np.zeros((hsize,vsize,n_frames));\n",
    "    for i in range(0,n_frames):\n",
    "        frame = np.random.rand(hsize,vsize)*(2**16)\n",
    "        frame = frame.astype(int)\n",
    "        frames[:,:,i] = frame       # numpy nd array\n",
    "    data_raw[j*hsize:(j+1)*hsize,:] = np.concatenate(tuple(frames[:,:,i] for i in range(0,n_frames)), axis=1)       # 2d-array\n",
    "    \n",
    "# for i in range(0,n_frames-1):\n",
    "# frames[:,:,0] = np.concatenate(tuple(frames[:,:,i] for i in range(0,n_frames-1)), axis=1)\n",
    "# how to process the data?? prepare the data such that there is minimum memory consumption\n",
    "print(len(data_raw[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(data_raw[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the signal and reference for immediate plotting.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta for the case where 'data_raw' is a list\n",
    "# mean signal/reference ki sum naki average of the signal/reference frames ???\n",
    "# (ALWAYS use numpy arrays instead of python lists for faster performance)\n",
    "mean_sig = []; mean_ref = []\n",
    "for j in range(0, N_scanpts):\n",
    "    sum_of_signal_frames = []; sum_of_reference_frames = [];\n",
    "    sum_of_signal_frames.append(np.array([np.sum(all_frames[0][:,:,i]) for i in range(0, n_frames,2)]))\n",
    "    sum_of_reference_frames.append(np.array([np.sum(all_frames[0][:,:,i]) for i in range(1, n_frames,2)]))\n",
    "    mean_sig.append(np.mean(sum_of_signal_frames))\n",
    "    mean_ref.append(np.mean(sum_of_reference_frames))\n",
    "# done..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "format = \"%d\\t\"*10\n",
    "format = (format[0:-1]+\"\\n\")*5\n",
    "print(format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eta for the case when data_raw is a 2d-array\n",
    "# need the frame info - hsize, vsize, n_frames\n",
    "mean_sig = np.zeros(N_scanpts); mean_ref = np.zeros(N_scanpts);\n",
    "for i in range(0,N_scanpts):\n",
    "    # signal_frames = np.array([data_raw[i*vsize:(i+1)*vsize,j*hsize:(j+1)*hsize] for j in range(0,n_frames,2)])\n",
    "    # reference_frames = np.array([data_raw[i*vsize:(i+1)*vsize,j*hsize:(j+1)*hsize] for j in range(1,n_frames,2)])\n",
    "    sum_of_signal_frames = np.array([np.sum(data_raw[i*vsize:(i+1)*vsize,j*hsize:(j+1)*hsize]) for j in range(0,n_frames,2)])\n",
    "    sum_of_reference_frames = np.array([np.sum(data_raw[i*vsize:(i+1)*vsize,j*hsize:(j+1)*hsize]) for j in range(1,n_frames,2)])\n",
    "\n",
    "    mean_sig[i] = np.mean(sum_of_signal_frames)\n",
    "    mean_ref[i] = np.mean(sum_of_reference_frames)\n",
    "\n",
    "plt.plot(mean_sig); plt.plot(mean_ref); plt.legend(['Avg Sig', 'Avg Ref'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the data for saving -- SAMPLE code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do this ONLY when the data is stored other than the intended saving format\n",
    "# first signal and reference frames... a = all_frames[0]\n",
    "# signal frame is a[:,:,0] and reference frame is a[:,:,1]\n",
    "# then concat the two...\n",
    "a = np.concatenate(tuple(all_frames[4][:,:,i] for i in range(0,n_frames)), axis=1)\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing er command ta... (not required when the variable already stores in the intended manner).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the above for all the scan_pts, ie for all i in all_frames[i]\n",
    "data_raw = np.concatenate(tuple(np.concatenate(tuple(all_frames[j][:,:,i] for i in range(0,n_frames)), axis=1) for j in range(0,N_scanpts)), axis=0)\n",
    "\n",
    "# see that data_raw is a single nd array with (vsize*N_scanpts) rows and (2*hsize) columns... CHECK THIS FIRST AS TO WHAT SHOUD BE THE DIMENSION OF THE IMAGE.. RxC OR CxR ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_raw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally save the data to a file -- SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_format = \"\"\n",
    "for i in range(0, n_frames*vsize):\n",
    "    write_format += \"%d\\t\"\n",
    "write_format = write_format[0:-1]+\"\\n\"\n",
    "# write_format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The write format.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puro file ta ek bar e likhte gele eta...\n",
    "write_format = \"\"\n",
    "for j in range(0,N_scanpts*hsize):\n",
    "    for i in range(0, n_frames*vsize):\n",
    "        write_format += \"%d\\t\"\n",
    "    write_format = write_format[0:-1]+\"\\n\"\n",
    "    # print(write_format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file ta line by line likhte gele eta...\n",
    "write_format = \"\"\n",
    "for i in range(0, n_frames*vsize):\n",
    "    write_format += \"%d\\t\"\n",
    "write_format = write_format[0:-1]+\"\\n\"\n",
    "# print(write_format)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puro file ta ek bar e lekha...\n",
    "filename = \"trial1.txt\"\n",
    "datafile = open(filename, 'a')\n",
    "# for loop o kora jeto... kintu seta korle write_format ke paltate hoto.. per line info dite hoto..\n",
    "# for line in data_raw:\n",
    "    # datafile.write(write_format % tuple(line))\n",
    "    # print(tuple(line))\n",
    "# direct puro file ta write o kora jabe... w/o any loop.. use numpy.ravel().. returns a contiguous flattened array.\n",
    "datafile.write(write_format % tuple(data_raw.ravel()))\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(data_raw.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file ta line by line lekha...\n",
    "filename = \"trial8.txt\"\n",
    "datafile = open(filename, 'a')\n",
    "# for loop o kora jeto... kintu seta korle write_format ke paltate hoto.. per line info dite hoto..\n",
    "for line in data_raw:\n",
    "    datafile.write(write_format % tuple(line))\n",
    "    # print(tuple(line))\n",
    "# direct puro file ta write o kora jabe... w/o any loop.. use numpy.ravel().. returns a contiguous flattened array.\n",
    "# datafile.write(write_format % tuple(data_raw.ravel()))\n",
    "datafile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scannedParam gulo save kora....\n",
    "param = [i for i in range(0,10)]\n",
    "param\n",
    "tuple(i for i in param)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,10):\n",
    "plt.figure(); plt.imshow(all_frames[0][:,:,0],cmap='gray', vmin=0, vmax=2**16)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koto time lagchhe??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "times = []\n",
    "for i in range(0,100):\n",
    "    start = time.perf_counter_ns()\n",
    "    # put the statement here\n",
    "    data_write_format = \"%d\\t\" * 10*2048    # n_frames*hsize... na n_frames*vsize...\n",
    "    # puro file ta ekbar e likhe debo... niche...\n",
    "    data_write_format = (data_write_format[0:-1] + \"\\n\") * (1000*2048) # remove \\t at the end and add \\n\n",
    "    # file save korar ta sesh...\n",
    "    stop = time.perf_counter_ns()\n",
    "    times.append(stop-start)\n",
    "plt.figure(); plt.hist(times); plt.xlabel(\"Times [ns]\"); plt.ylabel(\"Occurence [arb]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Could not build capability 0x420830: ValueError('4327472 is not a valid EProp')\n",
      "WARNING:root:Could not build capability 0x420840: ValueError('4327488 is not a valid EProp')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;100;250;30mCamera Initialized..!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import Camcontrol as camctrl; import PBctrl_under_construc as PBctrl; import time; import numpy as np; import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "\n",
    "roi = [1076,1088,448,444]; Nsamples=2; cam = camctrl.open_camera();\n",
    "instructionList = [[[0, 0, 0, 5000.0], [12, 6, 0, 20000.0]], [[0, 0, 0, 5000.0], [8, 6, 0, 20000.0]]]\n",
    "t_exposure = 0.05; t_seq_total = [20000.0, 20000.0];\n",
    "cam[\"exposure_time\"] = t_exposure;\n",
    "camctrl.set_roi(cam,roi,status=True);\n",
    "\n",
    "hsize = roi[2]; vsize = roi[3]; \n",
    "\n",
    "frames=np.zeros((vsize,hsize,Nsamples),dtype=np.uint16);\n",
    "time_taken = []\n",
    "\n",
    "for i in range(0,1000):\n",
    "    # print(i)\n",
    "    stream = camctrl.ham.Stream(cam,Nsamples)   # the statement assigns the buffer according to the no of frames to acquire..\n",
    "    stream.__enter__()\n",
    "    start_time = time.perf_counter_ns()   # time in ns\n",
    "    camctrl.cam.start()\n",
    "    end_time = time.perf_counter_ns()   # time in ns\n",
    "    # time.sleep(0.1)\n",
    "    PBctrl.run_sequence_for_camera(instructionList, t_exposure*1e9, t_seq_total)\n",
    "    for i, frame_buffer in enumerate(stream):\n",
    "        frame = camctrl.ham.copy_frame(frame_buffer)\n",
    "        frames[:,:,i] = frame\n",
    "    stream.__exit__()\n",
    "    PBctrl.pb_stop()\n",
    "    # plt.figure(); plt.imshow(frames[:,:,1],vmin=0,vmax=2**16);\n",
    "    time_taken.append((end_time-start_time)/1e6)    # time_taken in ms\n",
    "plt.figure(); plt.hist(time_taken);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273.1735"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.hist(time_taken,500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Time taken by 'cam.start()' command (1000 trials)\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.title(\"Time taken by 'cam.start()' command (1000 trials)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(46.972222222222214, 0.5, 'Occurences')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.xlabel('Time taken [ms]'); plt.ylabel('Occurences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260.0, 280.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.xlim((260,280))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Sep  7 14:26:03 2021\n",
    "\n",
    "@author: PC\n",
    "\"\"\"\n",
    "#%%\n",
    "from spinapi import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "\n",
    "pb_init()\n",
    "pb_get_version()\n",
    "pb_core_clock(500)\n",
    "ONE_PERIOD = 0x200000\n",
    "# shortpulseFLAG = ONE_PERIOD\n",
    "\n",
    "pb_start_programming(PULSE_PROGRAM)\n",
    "on_time  = 500 *ms\n",
    "off_time = 500 *ms\n",
    "# start = pb_inst_pbonly(shortpulseFLAG^11, Inst.CONTINUE, 0, on_time)\n",
    "start = pb_inst_pbonly(0b1000, Inst.CONTINUE,0,on_time)\n",
    "pb_inst_pbonly(0b1000, Inst.BRANCH, start, off_time)\n",
    "pb_stop_programming()\n",
    "\n",
    "pb_reset()\n",
    "pb_start()\n",
    "time_taken=[]\n",
    "for i in range(0,1000):\n",
    "    start_time = time.perf_counter_ns()   # time in ns\n",
    "    pb_stop()\n",
    "    end_time = time.perf_counter_ns()   # time in ns\n",
    "    time_taken.append((end_time-start_time)/1e3)  # time_taken in us\n",
    "# print(\"Enter any key to stop\")\n",
    "# input(\"Enter any key to stop: \") \n",
    "\n",
    "# pb_stop()\n",
    "pb_close()\n",
    "\n",
    "#%% Reset the PB\n",
    "pb_init(); pb_stop(); pb_close()\n",
    "plt.figure(); plt.hist(time_taken,100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.6,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.7,\n",
       " 3.7,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.5,\n",
       " 3.4,\n",
       " 3.5,\n",
       " 3.3,\n",
       " 3.7,\n",
       " 3.3,\n",
       " 3.3,\n",
       " 6.7,\n",
       " 3.4,\n",
       " 3.8,\n",
       " 3.7,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.8,\n",
       " 3.4,\n",
       " 3.5,\n",
       " 3.4,\n",
       " 3.5,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.5,\n",
       " 3.5,\n",
       " 3.4,\n",
       " 4.1,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.3,\n",
       " 3.3,\n",
       " 3.5,\n",
       " 3.4,\n",
       " 3.3,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.5,\n",
       " 3.3,\n",
       " 3.8,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.6,\n",
       " 3.5,\n",
       " 3.3,\n",
       " 3.5,\n",
       " 3.4,\n",
       " 3.4,\n",
       " 3.6,\n",
       " 3.4,\n",
       " 3.5,\n",
       " 3.7,\n",
       " 3.4,\n",
       " 3.4]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(tuple(frames[:,:,j] for j in range(0,n_frames)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([np.sum(np.array([j, j+1, j+2])) for j in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.sum(data_raw[i*vsize:(i+1)*vsize,j*hsize:(j+1)*hsize]) for j in range(0,n_frames,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = [i for i in range(0,10)]\n",
    "t_manip = np.array(param)\n",
    "t_seq_total0 = 100 + t_manip\n",
    "t_seq_total1 = 10 + t_manip\n",
    "t_seq_total = np.transpose(np.array([t_seq_total0, t_seq_total1]))\n",
    "t_seq_total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using OpenCV for image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# print(cv2.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "img_path = \"camera_image.txt\"\n",
    "\n",
    "img = np.loadtxt(img_path, delimiter=\"\\t\")\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "# cv2.resizeWindow(\"Image\", shape[1], shape[0])\n",
    "im = cv2.imshow(\"Image\",frames)\n",
    "cv2.applyColorMap(im, cv2.COLORMAP_JET)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = cv2.selectROI(img)\n",
    "plt.figure();\n",
    "plt.subplot(121); plt.imshow(img); plt.Rectangle((roi[0],roi[1]),roi[2],roi[3])\n",
    "plt.imshow(img); plt.gca().add_patch(plt.Rectangle((roi[0],roi[1]),roi[2],roi[3],edgecolor='r',facecolor='none'))\n",
    "cropped = img[roi[1]:(roi[1]+roi[3]),roi[0]:(roi[0]+roi[2])]\n",
    "plt.subplot(122); plt.imshow(cropped)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cropped[:,:,0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.selectROI()\n",
    "origin of the plot is the top left corner\n",
    "roi[0] and roi[1] = (x,y) of the top left corner of the selected ROI...\n",
    "roi[2] = hsize\n",
    "roi[3] = vsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camctrl.close_camera(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save a frame ... write a method in camctrl.. for a single frame\n",
    "path = \"D:\\\\Brateen\\\\Python_codes\\\\qdSpectro-active\\\\Saved_Data\\\\2023-06-26\\\\\"\n",
    "filename = \"camera_image_code.txt\"\n",
    "data=frame\n",
    "[vsize, hsize] = data.shape\n",
    "write_format = \"\"\n",
    "for i in range(0, hsize):\n",
    "    write_format += \"%d\\t\"\n",
    "write_format = write_format[0:-1] + \"\\n\"\n",
    "file = open(path+filename, 'w')\n",
    "for line in data:\n",
    "    file.write(write_format % tuple(line))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a file\n",
    "path = \"D:\\\\Brateen\\\\Python_codes\\\\qdSpectro-active\\\\Saved_Data\\\\2023-06-26\\\\\"\n",
    "filename = \"camera_image_code.txt\"\n",
    "original = np.loadtxt(path+filename, delimiter=\"\\t\")\n",
    "shape = original.shape\n",
    "plt.figure(\"hsize: %d, vsize: %d\" % (shape[1], shape[0])); plt.imshow(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# print(cv2.__version__)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "import Camcontrol as camctrl\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "cam = camctrl.open_camera()\n",
    "cam[\"exposure_time\"] = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[frame, roi] = camctrl.select_roi(cam)\n",
    "print(roi);\n",
    "plt.figure(); plt.imshow(frame,cmap='gray',vmin=0,vmax=2**16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam[\"subarray_mode\"].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[frame, roi] = camctrl.select_roi(cam) # select an ROI\n",
    "# print(roi);\n",
    "# plt.figure(); plt.imshow(frame);    # display the full frame...\n",
    "\n",
    "# roi = [0,900,300,1000]        # our ROI\n",
    "roi = [int(element/4)*4 for element in roi];\n",
    "\n",
    "# 'crop' the full frame to the given ROI\n",
    "plt.figure(\"Cropped Image: \"+str(roi));\n",
    "plt.subplot(121); plt.imshow(frame,cmap='gray', vmin=0, vmax=2**16);    # here frame is full resolution\n",
    "plt.gca().add_patch(plt.Rectangle((roi[0],roi[1]),roi[2],roi[3],edgecolor='r',facecolor='none'))\n",
    "cropped = frame[roi[1]:(roi[1]+roi[3]),roi[0]:(roi[0]+roi[2])]\n",
    "plt.subplot(122); plt.imshow(cropped,cmap='gray', vmin=0, vmax=2**16)\n",
    "\n",
    "# now acquire the given ROI from camera\n",
    "camctrl.set_roi(cam,roi,True)\n",
    "frames = camctrl.get_frames(cam,roi)\n",
    "print(frames.shape)\n",
    "plt.figure(\"ROI from camera\");\n",
    "plt.subplot(121); plt.imshow(frame,cmap='gray', vmin=0, vmax=2**16);\n",
    "plt.gca().add_patch(plt.Rectangle((roi[0],roi[1]),roi[2],roi[3],edgecolor='r',facecolor='none'))\n",
    "# frames = np.transpose(frames,(1,0))\n",
    "plt.subplot(122); plt.imshow(frames,cmap='gray', vmin=0, vmax=2**16)\n",
    "plt.title(\"vsize: %d, hsize: %d\" % ((frames.shape)[0], (frames.shape)[1]))\n",
    "\n",
    "# cv2.namedWindow(\"Full Res Image (2048x2048)\", cv2.WINDOW_NORMAL)\n",
    "# for i in range(0,10):\n",
    "# camctrl.live_view(cam)\n",
    "    # cv2.imshow(\"Full Res Image (2048x2048)\", frame)\n",
    "    # cv2.waitKey(1)\n",
    "    # time.sleep(1)\n",
    "    # cv2.imshow(\"A\", frame)\n",
    "    # time.pause(0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = [0,0,1000,500]\n",
    "# roi = camctrl.select_roi(cam)\n",
    "roi = [int(element/4)*4 for element in roi];\n",
    "camctrl.set_roi(cam,roi,True)\n",
    "frames = camctrl.get_frames(cam,roi)\n",
    "plt.figure(); plt.imshow(frames); plt.title(\"W: %d, H: %d\" %(frames.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.imshow(frames, vmin=0, vmax=2**16)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i) for i in range(0,2)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ki je hochhe \"frames\" er...????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = np.zeros(np.transpose(frames).shape)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = frame.shape\n",
    "shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = frame.shape\n",
    "f1 = np.zeros((100,200))\n",
    "f2 = np.zeros((100,200))\n",
    "f3 = np.zeros((100,200))\n",
    "for v in range(0,int(shape[0]/3)):\n",
    "    f1[v,:] = frame[3*v,:]\n",
    "    f2[v,:] = frame[3*v+1,:]\n",
    "    f3[v,:] = frame[3*v+2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.imshow(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "roi = [1600,900,300,200]        # our ROI\n",
    "roi = [int(element/4)*4 for element in roi];\n",
    "\n",
    "# 'crop' the full frame to the given ROI\n",
    "plt.figure(\"Cropped Image: \"+str(roi));\n",
    "plt.subplot(121); plt.imshow(original,cmap='gray', vmin=0, vmax=2**16);    # here frame is full resolution\n",
    "plt.gca().add_patch(plt.Rectangle((roi[0],roi[1]),roi[2],roi[3],edgecolor='r',facecolor='none'))\n",
    "cropped = original[roi[1]:(roi[1]+roi[3]),roi[0]:(roi[0]+roi[2])]\n",
    "plt.subplot(122); plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(); plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = np.zeros(np.transpose(frames).shape)\n",
    "shape=frames.shape\n",
    "asp_ratio = shape[1]/shape[0] if shape[1]>shape[0] else shape[0]/shape[1]\n",
    "print(\"f1: %d x %d\" % f1.shape)\n",
    "print(\"frames: %d x %d\" % frames.shape)\n",
    "for i in range(0,(frames.shape)[0],2):\n",
    "    # print(i)\n",
    "    f1[int(i/asp_ratio),:] = np.concatenate((frames[i,:], frames[i+1,:]))\n",
    "plt.figure(\"Thik Image\");plt.imshow(f1)\n",
    "plt.figure(\"Baje Image\");plt.imshow(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[frame, roi] = camctrl.select_roi(cam)\n",
    "print(roi)\n",
    "# display the cropped area\n",
    "# cv2.namedWindow(\"Image\", cv2.WINDOW_KEEPRATIO)\n",
    "# cv2.imshow(\"Image\", frame)\n",
    "plt.figure();\n",
    "plt.subplot(121); plt.imshow(frame); plt.gca().add_patch(plt.Rectangle((roi[0],roi[1]),roi[2],roi[3],edgecolor='r',facecolor='none'))\n",
    "cropped = frame[roi[1]:(roi[1]+roi[3]),roi[0]:(roi[0]+roi[2])]\n",
    "plt.subplot(122); plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure();\n",
    "plt.subplot(121); #plt.imshow(frame); plt.Rectangle((roi[0],roi[1]),roi[2],roi[3])\n",
    "plt.imshow(frame); plt.gca().add_patch(plt.Rectangle((roi[0],roi[1]),roi[2],roi[3],edgecolor='r',facecolor='none'))\n",
    "cropped = frame[roi[1]:(roi[1]+roi[3]),roi[0]:(roi[0]+roi[2])]\n",
    "plt.subplot(122); plt.imshow(cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"A\", cv2.WINDOW_NORMAL)\n",
    "cv2.imshow(\"A\", frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"ROI\", cv2.WINDOW_NORMAL) \n",
    "roi = cv2.select_roi(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyQt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "import sys\n",
    " \n",
    "class Ui_MainWindow(QtWidgets.QWidget):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.resize(422, 255)\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    " \n",
    "        self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(160, 130, 93, 28))\n",
    " \n",
    "        # For displaying confirmation message along with user's info.\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)   \n",
    "        self.label.setGeometry(QtCore.QRect(170, 40, 201, 111))\n",
    " \n",
    "        # Keeping the text of label empty initially.      \n",
    "        self.label.setText(\"\")    \n",
    " \n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    " \n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.pushButton.setText(_translate(\"MainWindow\", \"Proceed\"))\n",
    "        self.pushButton.clicked.connect(self.takeinputs)\n",
    "         \n",
    "    def takeinputs(self):\n",
    "        # name, done1 = QtWidgets.QInputDialog.getText(\n",
    "            #  self, 'Input Dialog', 'Enter your name:')\n",
    "        # for i in range(0,10):\n",
    "        roll, done2 = QtWidgets.QInputDialog.getInt(self, 'Input Dialog', 'Enter your roll:') \n",
    "        print(roll)\n",
    "        # cgpa, done3 = QtWidgets.QInputDialog.getDouble(\n",
    "            #   self, 'Input Dialog', 'Enter your CGPA:')\n",
    "        \n",
    "        # langs =['C', 'c++', 'Java', 'Python', 'Javascript']\n",
    "        # lang, done4 = QtWidgets.QInputDialog.getItem(\n",
    "        #   self, 'Input Dialog', 'Language you know:', langs)\n",
    " \n",
    "        # if done1 and done2 and done3 and done4 :\n",
    "        #      # Showing confirmation message along\n",
    "        #      # with information provided by user.\n",
    "        #      self.label.setText('Information stored Successfully\\nName: '\n",
    "        #                          +str(name)+'('+str(roll)+')'+'\\n'+'CGPA: '\n",
    "        #                          +str(cgpa)+'\\nSelected Language: '+str(lang))  \n",
    "  \n",
    "        #      # Hide the pushbutton after inputs provided by the use.\n",
    "        #      self.pushButton.hide()     \n",
    "               \n",
    "              \n",
    "              \n",
    "if __name__ == \"__main__\":\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    " \n",
    "    sys.exit(app.exec_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another example code... cholei na...\n",
    "import sys\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *\n",
    "from PyQt5.QtWidgets import *\n",
    "\n",
    "class inputdialogdemo(QtWidgets):\n",
    "   def __init__(self, parent = None):\n",
    "      super(inputdialogdemo, self).__init__(parent)\n",
    "\t\t\n",
    "      layout = QFormLayout()\n",
    "      self.btn = QPushButton(\"Choose from list\")\n",
    "      self.btn.clicked.connect(self.getItem)\n",
    "\t\t\n",
    "      self.le = QLineEdit()\n",
    "      layout.addRow(self.btn,self.le)\n",
    "      self.btn1 = QPushButton(\"get name\")\n",
    "      self.btn1.clicked.connect(self.gettext)\n",
    "\t\t\n",
    "      self.le1 = QLineEdit()\n",
    "      layout.addRow(self.btn1,self.le1)\n",
    "      self.btn2 = QPushButton(\"Enter an integer\")\n",
    "      self.btn2.clicked.connect(self.getint)\n",
    "\t\t\n",
    "      self.le2 = QLineEdit()\n",
    "      layout.addRow(self.btn2,self.le2)\n",
    "      self.setLayout(layout)\n",
    "      self.setWindowTitle(\"Input Dialog demo\")\n",
    "\t\t\n",
    "   def getItem(self):\n",
    "      items = (\"C\", \"C++\", \"Java\", \"Python\")\n",
    "\t\t\n",
    "      item, ok = QInputDialog.getItem(self, \"select input dialog\", \n",
    "         \"list of languages\", items, 0, False)\n",
    "\t\t\t\n",
    "      if ok and item:\n",
    "         self.le.setText(item)\n",
    "\t\t\t\n",
    "   def gettext(self):\n",
    "      text, ok = QInputDialog.getText(self, 'Text Input Dialog', 'Enter your name:')\n",
    "\t\t\n",
    "      if ok:\n",
    "         self.le1.setText(str(text))\n",
    "\t\t\t\n",
    "   def getint(self):\n",
    "      num,ok = QInputDialog.getInt(self,\"integer input dualog\",\"enter a number\")\n",
    "\t\t\n",
    "      if ok:\n",
    "         self.le2.setText(str(num))\n",
    "\t\t\t\n",
    "def main(): \n",
    "   app = QApplication(sys.argv)\n",
    "   ex = inputdialogdemo()\n",
    "   ex.show()\n",
    "   sys.exit(app.exec_())\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "   main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulate interactive increase of exposure time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "# import Camcontrol as camctrl\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "# cam = camctrl.open_camera()\n",
    " \n",
    "class Ui_MainWindow(QtWidgets.QWidget):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.resize(422, 255)\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    " \n",
    "        self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(160, 130, 93, 28))\n",
    " \n",
    "        # For displaying confirmation message along with user's info.\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)   \n",
    "        self.label.setGeometry(QtCore.QRect(170, 40, 201, 111))\n",
    " \n",
    "        # Keeping the text of label empty initially.      \n",
    "        self.label.setText(\"\")    \n",
    " \n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "        \n",
    " \n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.pushButton.setText(_translate(\"MainWindow\", \"Proceed\"))\n",
    "        self.pushButton.clicked.connect(self.takeinputs)\n",
    "\n",
    "    def takeinputs(self):\n",
    "        img = cv2.imread('1.jpg');\n",
    "        cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"Image\",img);\n",
    "        while True:\n",
    "            # key = cv2.waitKey(1)\n",
    "            time, done2 = QtWidgets.QInputDialog.getInt(self, 'Exposure', 'Enter a number:')\n",
    "            if not done2:\n",
    "                cv2.destroyAllWindows()\n",
    "                # MainWindow.close()\n",
    "                break\n",
    "            # img = img-time\n",
    "            cv2.imshow(\"Image\",(img-time))\n",
    "            # print(roll)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    \n",
    "    app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtCore, QtGui, QtWidgets\n",
    "import Camcontrol as camctrl\n",
    "import sys\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt\n",
    "plt.ion()\n",
    "\n",
    "cam = camctrl.open_camera()\n",
    " \n",
    "class Ui_MainWindow(QtWidgets.QWidget):\n",
    "    def setupUi(self, MainWindow):\n",
    "        MainWindow.resize(422, 255)\n",
    "        self.centralwidget = QtWidgets.QWidget(MainWindow)\n",
    " \n",
    "        self.pushButton = QtWidgets.QPushButton(self.centralwidget)\n",
    "        self.pushButton.setGeometry(QtCore.QRect(160, 130, 93, 28))\n",
    " \n",
    "        # For displaying confirmation message along with user's info.\n",
    "        self.label = QtWidgets.QLabel(self.centralwidget)   \n",
    "        self.label.setGeometry(QtCore.QRect(170, 40, 201, 111))\n",
    " \n",
    "        # Keeping the text of label empty initially.      \n",
    "        self.label.setText(\"\")    \n",
    " \n",
    "        MainWindow.setCentralWidget(self.centralwidget)\n",
    "        self.retranslateUi(MainWindow)\n",
    "        QtCore.QMetaObject.connectSlotsByName(MainWindow)\n",
    "        \n",
    " \n",
    "    def retranslateUi(self, MainWindow):\n",
    "        _translate = QtCore.QCoreApplication.translate\n",
    "        MainWindow.setWindowTitle(_translate(\"MainWindow\", \"MainWindow\"))\n",
    "        self.pushButton.setText(_translate(\"MainWindow\", \"Proceed\"))\n",
    "        self.pushButton.clicked.connect(self.takeinputs)\n",
    "\n",
    "    def takeinputs(self):\n",
    "        # inp = QtWidgets.QInputDialog(self)\n",
    "        # cv2.namedWindow(\"Live: Hit 'Space' to exit\", cv2.WINDOW_NORMAL)\n",
    "        # frame = camctrl.get_frames(cam)\n",
    "        # shape = frame.shape\n",
    "        # cv2.resizeWindow(\"Image\", int(shape[1]/4), int(shape[0]/4))\n",
    "        # cv2.imshow(\"Live: Hit 'Space' to exit\", frame)\n",
    "        \n",
    "        # exp_time=100      # in ms (initial value for widget)\n",
    "        # while True:\n",
    "        #     exp_time, done2 = inp.getInt(self, 'Exposure', 'Enter exposure time [ms]:',value=exp_time,min=1,max=10000)\n",
    "        #     # self.close()\n",
    "        #     if not done2:\n",
    "        #         cv2.destroyAllWindows()\n",
    "        #         # MainWindow.close()\n",
    "        #         break\n",
    "        #     cam[\"exposure_time\"] = exp_time/1e3;\n",
    "        #     frames = camctrl.get_frames(cam);\n",
    "        #     shape = frames.shape\n",
    "        #     for i in range(0,shape[2]):\n",
    "        #         cv2.imshow(\"Live: Hit 'Space' to exit\", frames[:,:,i])\n",
    "        plt.figure(\"Set Exposure\")\n",
    "        exp_time=10;\n",
    "        cam[\"exposure_time\"] = exp_time/1e3;    # in ms (initial value for widget)\n",
    "        frames = camctrl.get_frames(cam);        shape = frames.shape\n",
    "        plt.imshow(frames,vmin=0,vmax=2**16); plt.colorbar()\n",
    "        while True:\n",
    "            exp_time, done2 = QtWidgets.QInputDialog.getInt(self, 'Exposure', 'Enter exposure time [ms]:',value=exp_time,min=1,max=10000)\n",
    "            if not done2:\n",
    "                plt.close(\"Set Exposure\")\n",
    "                break\n",
    "            cam[\"exposure_time\"] = exp_time/1e3;    # needs to be set in seconds, \"exp_time\" in ms\n",
    "            frames = camctrl.get_frames(cam);\n",
    "            # shape = frames.shape\n",
    "            # for i in range(0,shape[2]):\n",
    "            plt.imshow(frames,vmin=0,vmax=2**16)\n",
    "            plt.pause(0.000001)\n",
    "            # plt.show()\n",
    "        app.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app = QtWidgets.QApplication(sys.argv)\n",
    "    MainWindow = QtWidgets.QMainWindow()\n",
    "    ui = Ui_MainWindow()\n",
    "    ui.setupUi(MainWindow)\n",
    "    MainWindow.show()\n",
    "    \n",
    "    app.exec_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "img = cv2.imread(\"1.jpg\")\n",
    "cv2.imshow(\"Image\",img)\n",
    "img-1\n",
    "# img+1\n",
    "# roi = cv2.selectROI(\"Image\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.genfromtxt(\"D:\\\\Brateen\\\\Python_codes\\\\qdSpectro-active\\\\Saved_Data\\\\2023-06-29\\\\Rabi_camera_3.txt\",delimiter=\"\\t\",skip_header=1,max_rows=57536)\n",
    "# param = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13808641,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1,2,3,4,5,6,0]]\n",
    "a = a[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a34074c520>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "plt.plot(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fontsize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-74db4075ebf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ajhfj\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fontsize' is not defined"
     ]
    }
   ],
   "source": [
    "plt.title(\"Ajhfj\", fontsize,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function a at 0x0000024F484B9670>\n"
     ]
    }
   ],
   "source": [
    "def a():\n",
    "    j=0;\n",
    "    for i in range(0,int(1e7)):\n",
    "        j+=1;\n",
    "    return j\n",
    "def make_rabi_seq():\n",
    "    i=2\n",
    "    return i\n",
    "\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib qt5\n",
    "\n",
    "times = []\n",
    "for i in range(0,10):\n",
    "    start = time.perf_counter_ns()\n",
    "    # put the statement here\n",
    "    x = {'a':a, 'b':a}\n",
    "    stop = time.perf_counter_ns()\n",
    "    times.append(stop-start)\n",
    "plt.figure(); plt.hist(times); plt.xlabel(\"Times [ns]\"); plt.ylabel(\"Occurence [arb]\");\n",
    "print(x['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': <function __main__.a()>, 'b': <function __main__.a()>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[28, 0, 0, 100.0],\n",
       "  [12, 0, 0, 19800.0],\n",
       "  [14, 0, 0, 100.0],\n",
       "  [8, 0, 0, 19900.0],\n",
       "  [10, 6, 0, 100.0]]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the_list = [[[[28, 0, 0, 100.0], [12, 0, 0, 19800.0], [14, 0, 0, 100.0], [8, 0, 0, 19900.0], [10, 6, 0, 100.0]], 0, [], [], {0: 0.0, 1: 0.1, 2: 19.9, 3: 20.0, 4: 39.9}]]\n",
    "instructionList = []\n",
    "for i in range(0,len(the_list)):\n",
    "    instructionList.append(the_list[i][0])\n",
    "instructionList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[28, 0, 0, 100.0],\n",
       " [12, 0, 0, 19800.0],\n",
       " [14, 0, 0, 100.0],\n",
       " [8, 0, 0, 19900.0],\n",
       " [10, 6, 0, 100.0]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructionList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "cts = [[i for i in range(0,10)], [i for i in range(100,110)]]     # cts for multi-channel acquisitions\n",
    "# cts = [[99]] + cts\n",
    "cts = np.ravel(np.array(cts))\n",
    "# cts = np.insert(np.ravel(np.array(cts)),0,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts = np.array((cts,cts,cts))\n",
    "cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  99,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "         100,  101,  102,  103,  104,  105,  106,  107,  108,  109],\n",
       "       [ 999,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "         100,  101,  102,  103,  104,  105,  106,  107,  108,  109],\n",
       "       [9999,    0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "         100,  101,  102,  103,  104,  105,  106,  107,  108,  109]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts = np.insert(cts,0,[99,999,9999],axis=1)\n",
    "cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 99,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101,\n",
       "        102, 103, 104, 105, 106, 107, 108, 109],\n",
       "       [ 99,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101,\n",
       "        102, 103, 104, 105, 106, 107, 108, 109],\n",
       "       [ 99,   0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101,\n",
       "        102, 103, 104, 105, 106, 107, 108, 109]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109],\n",
       "       [  0,   1,   2,   3,   4,   5,   6,   7,   8,   9, 100, 101, 102,\n",
       "        103, 104, 105, 106, 107, 108, 109]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   2,   4,   6,   8, 100, 102, 104, 106, 108],\n",
       "       [  0,   2,   4,   6,   8, 100, 102, 104, 106, 108],\n",
       "       [  0,   2,   4,   6,   8, 100, 102, 104, 106, 108]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts[:,[i for i in range(0,20,2)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.mean(cts[:,[i for i in range(0,20,2)]],axis=1)\n",
    "reference = np.mean(cts[:,[i for i in range(1,20,2)]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.01851852, 1.01851852, 1.01851852])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrast = np.divide(reference,signal)\n",
    "contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([i for i in range(0,10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [i for i in range(0,20)]\n",
    "np.reshape(a,(2,10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
